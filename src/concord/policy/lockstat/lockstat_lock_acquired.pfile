struct time_stat{
	unsigned long min;
	unsigned long max;
	unsigned long total;
};

struct data_t{
	/* User-defined additional data */
	unsigned long prev_cpu;

	/* lock_to_enter_slow_path */
	unsigned long contentions;
	unsigned long con_bounces;
	struct time_stat waittime;

	/* lock_acquired */
	unsigned long acquisitions;
	unsigned long acq_bounces;
	struct time_stat holdtime;

};

struct bpf_map_def SEC("maps") hash_map = {
	.type = BPF_MAP_TYPE_HASH,
	.key_size = sizeof(unsigned long),
	.value_size = sizeof(struct data_t),
	.max_entries = 10000,
};

SEC("lock_qspinlock_global")
int custom_lock_acquired(struct __lock_policy_args *args)
{
	unsigned long key = args->lock_ptr;
	struct data_t *data_ptr;
	data_ptr = bpf_map_lookup_elem(&hash_map, &key);

	if(!data_ptr){
		/** need to create new element */
		struct data_t data;
		data.prev_cpu= 0;
		data.contentions = 0;
		data.con_bounces = 0;
		data.waittime.min = 0;
		data.waittime.max = 0;
		data.waittime.total = 0;

		data.acquisitions = 0;
		data.acq_bounces = 0;
		data.holdtime.min = 0;
		data.holdtime.max = 0;
		data.holdtime.total = 0;

		bpf_map_update_elem(&hash_map, &key, &data, BPF_ANY);
		data_ptr = &data;
	}

	data_ptr->acquisitions++;

	// waittime stat
	if (args->per_cpu_data != 0){
		unsigned long waittime = bpf_ktime_get_ns() - args->per_cpu_data;
		data_ptr->waittime.total += waittime;
		data_ptr->waittime.min = data_ptr->waittime.min > waittime ? waittime : data_ptr->waittime.min;
		data_ptr->waittime.max = data_ptr->waittime.max < waittime ? waittime : data_ptr->waittime.max;
	}

	args->hold_start = bpf_ktime_get_ns();

	unsigned long curr_cpu= bpf_get_smp_processor_id();
	if(data_ptr->prev_cpu != curr_cpu) {
		data_ptr->acq_bounces++;

		if(args->per_cpu_data != 0){
			// this node was contended
			data_ptr->con_bounces++;
		}
	}

	//clean aux data
	data_ptr->prev_cpu = curr_cpu;
	args->per_cpu_data = 0;

	return 0;
}
