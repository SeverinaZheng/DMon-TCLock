diff -ruN SynCord-linux-base/arch/arm/kernel/process.c SynCord-linux-destination/arch/arm/kernel/process.c
--- SynCord-linux-base/arch/arm/kernel/process.c	2023-09-13 14:41:42.949347476 +0000
+++ SynCord-linux-destination/arch/arm/kernel/process.c	2023-09-15 09:09:47.862613787 +0000
@@ -6,6 +6,7 @@
  *  Original Copyright (C) 1995  Linus Torvalds
  */
 #include <stdarg.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/export.h>
 #include <linux/sched.h>
@@ -414,6 +415,7 @@
 
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long npages;
@@ -429,7 +431,7 @@
 	npages = 1; /* for sigpage */
 	npages += vdso_total_pages;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 	hint = sigpage_addr(mm, npages);
 	addr = get_unmapped_area(NULL, hint, npages << PAGE_SHIFT, 0, 0);
diff -ruN SynCord-linux-base/arch/arm64/kernel/vdso.c SynCord-linux-destination/arch/arm64/kernel/vdso.c
--- SynCord-linux-base/arch/arm64/kernel/vdso.c	2023-09-13 14:41:43.557346223 +0000
+++ SynCord-linux-destination/arch/arm64/kernel/vdso.c	2023-09-15 09:09:44.166615886 +0000
@@ -23,6 +23,7 @@
 #include <vdso/datapage.h>
 #include <vdso/helpers.h>
 #include <vdso/vsyscall.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/cacheflush.h>
 #include <asm/signal32.h>
@@ -354,10 +355,11 @@
 
 int aarch32_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	int ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	ret = aarch32_kuser_helpers_setup(mm);
@@ -415,10 +417,11 @@
 int arch_setup_additional_pages(struct linux_binprm *bprm,
 				int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	int ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	ret = __setup_additional_pages(ARM64_VDSO,
diff -ruN SynCord-linux-base/arch/hexagon/kernel/vdso.c SynCord-linux-destination/arch/hexagon/kernel/vdso.c
--- SynCord-linux-base/arch/hexagon/kernel/vdso.c	2023-09-13 14:41:43.673345986 +0000
+++ SynCord-linux-destination/arch/hexagon/kernel/vdso.c	2023-09-15 09:09:49.794612693 +0000
@@ -9,6 +9,7 @@
 #include <linux/mm.h>
 #include <linux/vmalloc.h>
 #include <linux/binfmts.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/vdso.h>
 
@@ -48,11 +49,12 @@
  */
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	int ret;
 	unsigned long vdso_base;
 	struct mm_struct *mm = current->mm;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	/* Try to get it loaded right near ld.so/glibc. */
diff -ruN SynCord-linux-base/arch/mips/kernel/vdso.c SynCord-linux-destination/arch/mips/kernel/vdso.c
--- SynCord-linux-base/arch/mips/kernel/vdso.c	2023-09-13 14:41:44.169344990 +0000
+++ SynCord-linux-destination/arch/mips/kernel/vdso.c	2023-09-15 09:09:53.422610641 +0000
@@ -15,6 +15,7 @@
 #include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/timekeeper_internal.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/abi.h>
 #include <asm/mips-cps.h>
@@ -86,13 +87,14 @@
 
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mips_vdso_image *image = current->thread.abi->vdso;
 	struct mm_struct *mm = current->mm;
 	unsigned long gic_size, vvar_size, size, base, data_addr, vdso_addr, gic_pfn;
 	struct vm_area_struct *vma;
 	int ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	/* Map delay slot emulation page */
diff -ruN SynCord-linux-base/arch/nds32/kernel/vdso.c SynCord-linux-destination/arch/nds32/kernel/vdso.c
--- SynCord-linux-base/arch/nds32/kernel/vdso.c	2023-09-13 14:41:44.317344705 +0000
+++ SynCord-linux-destination/arch/nds32/kernel/vdso.c	2023-09-15 09:09:49.446612890 +0000
@@ -16,6 +16,7 @@
 #include <linux/timekeeper_internal.h>
 #include <linux/vmalloc.h>
 #include <linux/random.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/cacheflush.h>
 #include <asm/vdso.h>
@@ -113,6 +114,7 @@
 
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	unsigned long vdso_base, vdso_text_len, vdso_mapping_len;
 	struct vm_area_struct *vma;
@@ -130,7 +132,7 @@
 	vdso_mapping_len += L1_cache_info[DCACHE].aliasing_num - 1;
 #endif
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	addr = vdso_random_addr(vdso_mapping_len);
diff -ruN SynCord-linux-base/arch/powerpc/kernel/vdso.c SynCord-linux-destination/arch/powerpc/kernel/vdso.c
--- SynCord-linux-base/arch/powerpc/kernel/vdso.c	2023-09-13 14:41:46.453340807 +0000
+++ SynCord-linux-destination/arch/powerpc/kernel/vdso.c	2023-09-15 09:09:56.018609177 +0000
@@ -17,6 +17,7 @@
 #include <linux/elf.h>
 #include <linux/security.h>
 #include <linux/memblock.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/pgtable.h>
 #include <asm/processor.h>
@@ -125,6 +126,7 @@
  */
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct page **vdso_pagelist;
 	unsigned long vdso_pages;
@@ -171,7 +173,7 @@
 	 * and end up putting it elsewhere.
 	 * Add enough to the size so that the result can be aligned.
 	 */
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 	vdso_base = get_unmapped_area(NULL, vdso_base,
 				      (vdso_pages << PAGE_SHIFT) +
diff -ruN SynCord-linux-base/arch/s390/kernel/vdso.c SynCord-linux-destination/arch/s390/kernel/vdso.c
--- SynCord-linux-base/arch/s390/kernel/vdso.c	2023-09-13 14:41:46.733340331 +0000
+++ SynCord-linux-destination/arch/s390/kernel/vdso.c	2023-09-15 09:09:50.646612210 +0000
@@ -28,6 +28,7 @@
 #include <asm/sections.h>
 #include <asm/vdso.h>
 #include <asm/facility.h>
+#include <linux/my_bpf_down_write.h>
 
 #ifdef CONFIG_COMPAT_VDSO
 extern char vdso32_start, vdso32_end;
@@ -200,6 +201,7 @@
  */
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long vdso_pages;
@@ -227,7 +229,7 @@
 	 * it at vdso_base which is the "natural" base for it, but we might
 	 * fail and end up putting it elsewhere.
 	 */
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 	vdso_base = get_unmapped_area(NULL, 0, vdso_pages << PAGE_SHIFT, 0, 0);
 	if (IS_ERR_VALUE(vdso_base)) {
diff -ruN SynCord-linux-base/arch/sh/kernel/vsyscall/vsyscall.c SynCord-linux-destination/arch/sh/kernel/vsyscall/vsyscall.c
--- SynCord-linux-base/arch/sh/kernel/vsyscall/vsyscall.c	2023-09-13 14:41:46.913340025 +0000
+++ SynCord-linux-destination/arch/sh/kernel/vsyscall/vsyscall.c	2023-09-15 09:09:44.838615504 +0000
@@ -15,6 +15,7 @@
 #include <linux/elf.h>
 #include <linux/sched.h>
 #include <linux/err.h>
+#include <linux/my_bpf_down_write.h>
 
 /*
  * Should the kernel map a VDSO page into processes and pass its
@@ -57,11 +58,12 @@
 /* Setup a VMA at program startup for the vsyscall page */
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	unsigned long addr;
 	int ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	addr = get_unmapped_area(NULL, 0, PAGE_SIZE, 0, 0);
diff -ruN SynCord-linux-base/arch/x86/entry/vdso/vma.c SynCord-linux-destination/arch/x86/entry/vdso/vma.c
--- SynCord-linux-base/arch/x86/entry/vdso/vma.c	2023-09-13 14:41:47.425339200 +0000
+++ SynCord-linux-destination/arch/x86/entry/vdso/vma.c	2023-09-15 09:09:57.358608421 +0000
@@ -23,6 +23,7 @@
 #include <asm/desc.h>
 #include <asm/cpufeature.h>
 #include <clocksource/hyperv_timer.h>
+#include <linux/my_bpf_down_write.h>
 
 #if defined(CONFIG_X86_64)
 unsigned int __read_mostly vdso64_enabled = 1;
@@ -145,12 +146,13 @@
  */
 static int map_vdso(const struct vdso_image *image, unsigned long addr)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long text_start;
 	int ret = 0;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	addr = get_unmapped_area(NULL, addr,
diff -ruN SynCord-linux-base/arch/x86/um/vdso/vma.c SynCord-linux-destination/arch/x86/um/vdso/vma.c
--- SynCord-linux-base/arch/x86/um/vdso/vma.c	2023-09-13 14:41:48.177338017 +0000
+++ SynCord-linux-destination/arch/x86/um/vdso/vma.c	2023-09-15 09:09:58.306607889 +0000
@@ -9,6 +9,7 @@
 #include <asm/page.h>
 #include <asm/elf.h>
 #include <linux/init.h>
+#include <linux/my_bpf_down_write.h>
 
 static unsigned int __read_mostly vdso_enabled = 1;
 unsigned long um_vdso_addr;
@@ -52,13 +53,14 @@
 
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
+	extern int num_policy;
 	int err;
 	struct mm_struct *mm = current->mm;
 
 	if (!vdso_enabled)
 		return 0;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	err = install_special_mapping(mm, um_vdso_addr, PAGE_SIZE,
diff -ruN SynCord-linux-base/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c SynCord-linux-destination/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c
--- SynCord-linux-base/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c	2023-09-13 14:41:51.329333639 +0000
+++ SynCord-linux-destination/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c	2023-09-15 09:09:02.198640123 +0000
@@ -46,6 +46,7 @@
 #include <linux/firmware.h>
 #include <linux/module.h>
 #include <drm/drm.h>
+#include <linux/my_bpf_down_write.h>
 
 #include "amdgpu.h"
 #include "amdgpu_amdkfd.h"
@@ -315,13 +316,14 @@
 struct amdgpu_mn *amdgpu_mn_get(struct amdgpu_device *adev,
 				enum amdgpu_mn_type type)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct amdgpu_mn *amn;
 	unsigned long key = AMDGPU_MN_KEY(mm, type);
 	int r;
 
 	mutex_lock(&adev->mn_lock);
-	if (down_write_killable(&mm->mmap_sem)) {
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 		mutex_unlock(&adev->mn_lock);
 		return ERR_PTR(-EINTR);
 	}
diff -ruN SynCord-linux-base/drivers/gpu/drm/i915/gem/i915_gem_mman.c SynCord-linux-destination/drivers/gpu/drm/i915/gem/i915_gem_mman.c
--- SynCord-linux-base/drivers/gpu/drm/i915/gem/i915_gem_mman.c	2023-09-13 14:41:52.117332667 +0000
+++ SynCord-linux-destination/drivers/gpu/drm/i915/gem/i915_gem_mman.c	2023-09-15 09:09:01.578640487 +0000
@@ -6,6 +6,7 @@
 
 #include <linux/mman.h>
 #include <linux/sizes.h>
+#include <linux/my_bpf_down_write.h>
 
 #include "gt/intel_gt.h"
 
@@ -85,10 +86,11 @@
 		goto err;
 
 	if (args->flags & I915_MMAP_WC) {
+		extern int num_policy;
 		struct mm_struct *mm = current->mm;
 		struct vm_area_struct *vma;
 
-		if (down_write_killable(&mm->mmap_sem)) {
+		if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 			addr = -EINTR;
 			goto err;
 		}
diff -ruN SynCord-linux-base/drivers/vfio/vfio_iommu_type1.c SynCord-linux-destination/drivers/vfio/vfio_iommu_type1.c
--- SynCord-linux-base/drivers/vfio/vfio_iommu_type1.c	2023-09-13 14:41:56.785327802 +0000
+++ SynCord-linux-destination/drivers/vfio/vfio_iommu_type1.c	2023-09-15 09:08:48.558648169 +0000
@@ -38,6 +38,7 @@
 #include <linux/notifier.h>
 #include <linux/dma-iommu.h>
 #include <linux/irqdomain.h>
+#include <linux/my_bpf_down_write.h>
 
 #define DRIVER_VERSION  "0.2"
 #define DRIVER_AUTHOR   "Alex Williamson <alex.williamson@redhat.com>"
@@ -267,6 +268,7 @@
 
 static int vfio_lock_acct(struct vfio_dma *dma, long npage, bool async)
 {
+	extern int num_policy;
 	struct mm_struct *mm;
 	int ret;
 
@@ -277,7 +279,7 @@
 	if (!mm)
 		return -ESRCH; /* process exited */
 
-	ret = down_write_killable(&mm->mmap_sem);
+	ret = my_bpf_down_write_killable(&mm->mmap_sem, num_policy);
 	if (!ret) {
 		ret = __account_locked_vm(mm, abs(npage), npage > 0, dma->task,
 					  dma->lock_cap);
diff -ruN SynCord-linux-base/fs/aio.c SynCord-linux-destination/fs/aio.c
--- SynCord-linux-base/fs/aio.c	2023-09-13 14:41:57.157327470 +0000
+++ SynCord-linux-destination/fs/aio.c	2023-09-15 09:09:39.506618540 +0000
@@ -21,6 +21,7 @@
 #include <linux/backing-dev.h>
 #include <linux/refcount.h>
 #include <linux/uio.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/sched/signal.h>
 #include <linux/fs.h>
@@ -459,6 +460,7 @@
 
 static int aio_setup_ring(struct kioctx *ctx, unsigned int nr_events)
 {
+	extern int num_policy;
 	struct aio_ring *ring;
 	struct mm_struct *mm = current->mm;
 	unsigned long size, unused;
@@ -519,7 +521,7 @@
 	ctx->mmap_size = nr_pages * PAGE_SIZE;
 	pr_debug("attempting mmap of %lu bytes\n", ctx->mmap_size);
 
-	if (down_write_killable(&mm->mmap_sem)) {
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 		ctx->mmap_size = 0;
 		aio_free_ring(ctx);
 		return -EINTR;
diff -ruN SynCord-linux-base/fs/coredump.c SynCord-linux-destination/fs/coredump.c
--- SynCord-linux-base/fs/coredump.c	2023-09-13 14:41:57.341327311 +0000
+++ SynCord-linux-destination/fs/coredump.c	2023-09-15 09:09:39.458618567 +0000
@@ -41,6 +41,7 @@
 #include <linux/fs.h>
 #include <linux/path.h>
 #include <linux/timekeeping.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -435,6 +436,7 @@
 
 static int coredump_wait(int exit_code, struct core_state *core_state)
 {
+	extern int num_policy;
 	struct task_struct *tsk = current;
 	struct mm_struct *mm = tsk->mm;
 	int core_waiters = -EBUSY;
@@ -443,7 +445,7 @@
 	core_state->dumper.task = tsk;
 	core_state->dumper.next = NULL;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	if (!mm->core_state)
diff -ruN SynCord-linux-base/fs/exec.c SynCord-linux-destination/fs/exec.c
--- SynCord-linux-base/fs/exec.c	2023-09-13 14:41:57.341327311 +0000
+++ SynCord-linux-destination/fs/exec.c	2023-09-15 09:09:39.354618627 +0000
@@ -63,6 +63,7 @@
 #include <linux/oom.h>
 #include <linux/compat.h>
 #include <linux/vmalloc.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -242,6 +243,7 @@
 
 static int __bprm_mm_init(struct linux_binprm *bprm)
 {
+	extern int num_policy;
 	int err;
 	struct vm_area_struct *vma = NULL;
 	struct mm_struct *mm = bprm->mm;
@@ -251,7 +253,7 @@
 		return -ENOMEM;
 	vma_set_anonymous(vma);
 
-	if (down_write_killable(&mm->mmap_sem)) {
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 		err = -EINTR;
 		goto err_free;
 	}
@@ -692,6 +694,7 @@
 		    unsigned long stack_top,
 		    int executable_stack)
 {
+	extern int num_policy;
 	unsigned long ret;
 	unsigned long stack_shift;
 	struct mm_struct *mm = current->mm;
@@ -739,7 +742,7 @@
 		bprm->loader -= stack_shift;
 	bprm->exec -= stack_shift;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	vm_flags = VM_STACK_FLAGS;
diff -ruN SynCord-linux-base/fs/proc/task_mmu.c SynCord-linux-destination/fs/proc/task_mmu.c
--- SynCord-linux-base/fs/proc/task_mmu.c	2023-09-13 14:41:58.753326131 +0000
+++ SynCord-linux-destination/fs/proc/task_mmu.c	2023-09-15 09:09:40.018618248 +0000
@@ -19,6 +19,7 @@
 #include <linux/shmem_fs.h>
 #include <linux/uaccess.h>
 #include <linux/pkeys.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/elf.h>
 #include <asm/tlb.h>
@@ -1166,7 +1167,8 @@
 		};
 
 		if (type == CLEAR_REFS_MM_HIWATER_RSS) {
-			if (down_write_killable(&mm->mmap_sem)) {
+			extern int num_policy;
+			if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 				count = -EINTR;
 				goto out_mm;
 			}
@@ -1187,10 +1189,11 @@
 		tlb_gather_mmu(&tlb, mm, 0, -1);
 		if (type == CLEAR_REFS_SOFT_DIRTY) {
 			for (vma = mm->mmap; vma; vma = vma->vm_next) {
+				extern int num_policy;
 				if (!(vma->vm_flags & VM_SOFTDIRTY))
 					continue;
 				up_read(&mm->mmap_sem);
-				if (down_write_killable(&mm->mmap_sem)) {
+				if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy)) {
 					count = -EINTR;
 					goto out_mm;
 				}
diff -ruN SynCord-linux-base/include/linux/my_bpf_down_write.h SynCord-linux-destination/include/linux/my_bpf_down_write.h
--- SynCord-linux-base/include/linux/my_bpf_down_write.h	1970-01-01 00:00:00.000000000 +0000
+++ SynCord-linux-destination/include/linux/my_bpf_down_write.h	2023-09-15 09:11:25.950560031 +0000
@@ -0,0 +1,8 @@
+#ifndef MY_BPF_SPIN_H
+#define MY_BPF_SPIN_H
+static int __must_check my_bpf_down_write_killable(struct rw_semaphore *sem, int policy)
+{
+	bpf_down_write(sem,policy);
+	return 0;
+}
+#endif
\ No newline at end of file
diff -ruN SynCord-linux-base/ipc/shm.c SynCord-linux-destination/ipc/shm.c
--- SynCord-linux-base/ipc/shm.c	2023-09-13 14:41:34.837369962 +0000
+++ SynCord-linux-destination/ipc/shm.c	2023-09-15 09:10:01.558606060 +0000
@@ -44,6 +44,7 @@
 #include <linux/mount.h>
 #include <linux/ipc_namespace.h>
 #include <linux/rhashtable.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uaccess.h>
 
@@ -1418,6 +1419,7 @@
 long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 	      ulong *raddr, unsigned long shmlba)
 {
+	extern int num_policy;
 	struct shmid_kernel *shp;
 	unsigned long addr = (unsigned long)shmaddr;
 	unsigned long size;
@@ -1544,7 +1546,7 @@
 	if (err)
 		goto out_fput;
 
-	if (down_write_killable(&current->mm->mmap_sem)) {
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy)) {
 		err = -EINTR;
 		goto out_fput;
 	}
@@ -1625,6 +1627,7 @@
  */
 long ksys_shmdt(char __user *shmaddr)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long addr = (unsigned long)shmaddr;
@@ -1638,7 +1641,7 @@
 	if (addr & ~PAGE_MASK)
 		return retval;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	/*
diff -ruN SynCord-linux-base/kernel/bpf/inode.c SynCord-linux-destination/kernel/bpf/inode.c
--- SynCord-linux-base/kernel/bpf/inode.c	2023-09-14 08:48:01.844831647 +0000
+++ SynCord-linux-destination/kernel/bpf/inode.c	2023-09-15 09:08:44.354650666 +0000
@@ -701,3 +701,77 @@
 	return ret;
 }
 fs_initcall(bpf_init);
+
+
+#include "kpatch-macros.h"
+#define MAX_POLICY 5
+
+static inline __u64 ptr_to_u64(const void *ptr)
+{
+    return (__u64) (unsigned long) ptr;
+}
+
+static void *get_pinned_bpf_obj(const char *pathname){
+	struct inode *inode;
+	struct path path;
+	void *raw;
+	int ret;
+
+	/* Let's get BPF prog 1 */
+	ret = kern_path(pathname, LOOKUP_FOLLOW, &path);
+	if (ret){
+		printk("[syncord] %s failed\n", pathname);
+		return ERR_PTR(ret);
+	}
+
+	inode = d_backing_inode(path.dentry);
+	ret = inode_permission(inode, ACC_MODE(2));
+	if(ret){
+		printk("[syncord] perm error\n");
+		path_put(&path);
+		return ERR_PTR(ret);
+	}
+
+	raw = bpf_any_get(inode->i_private, BPF_TYPE_PROG);
+	if(!IS_ERR(raw)){
+		touch_atime(&path);
+	}
+	else{
+		printk("[syncord] raw error\n");
+		path_put(&path);
+		return ERR_PTR(ret);
+	}
+
+	path_put(&path);
+	return raw;
+}
+
+static int pre_patch_callback(patch_object *obj)
+{
+	extern int num_policy;
+	extern void *bpf_prog_should_reorder_rwsem[MAX_POLICY];
+
+	if(num_policy < 4)
+		num_policy++;
+	else
+		return -1;
+
+	bpf_prog_should_reorder_rwsem[num_policy] = get_pinned_bpf_obj("/sys/fs/bpf/numa-grouping");
+	if(IS_ERR(bpf_prog_should_reorder_rwsem[num_policy])){
+		printk("[syncord] bpf_policy failed\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static void post_unpatch_callback(patch_object *obj) {
+	extern int num_policy;
+	extern void *bpf_prog_should_reorder_rwsem[MAX_POLICY];
+
+	bpf_prog_should_reorder_rwsem[num_policy] = NULL;
+	num_policy--;
+	klp_shadow_free_all(0, NULL);
+}
+KPATCH_PRE_PATCH_CALLBACK(pre_patch_callback);
+KPATCH_POST_UNPATCH_CALLBACK(post_unpatch_callback);
diff -ruN SynCord-linux-base/kernel/events/uprobes.c SynCord-linux-destination/kernel/events/uprobes.c
--- SynCord-linux-base/kernel/events/uprobes.c	2023-09-13 14:41:35.917366257 +0000
+++ SynCord-linux-destination/kernel/events/uprobes.c	2023-09-15 09:09:59.138607420 +0000
@@ -27,6 +27,7 @@
 #include <linux/task_work.h>
 #include <linux/shmem_fs.h>
 #include <linux/khugepaged.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uprobes.h>
 
@@ -1442,10 +1443,11 @@
 /* Slot allocation for XOL */
 static int xol_add_vma(struct mm_struct *mm, struct xol_area *area)
 {
+	extern int num_policy;
 	struct vm_area_struct *vma;
 	int ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	if (mm->uprobes_state.xol_area) {
diff -ruN SynCord-linux-base/kernel/fork.c SynCord-linux-destination/kernel/fork.c
--- SynCord-linux-base/kernel/fork.c	2023-09-13 14:41:35.597367344 +0000
+++ SynCord-linux-destination/kernel/fork.c	2023-09-15 09:09:59.658607128 +0000
@@ -94,6 +94,7 @@
 #include <linux/livepatch.h>
 #include <linux/thread_info.h>
 #include <linux/stackleak.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
@@ -478,6 +479,7 @@
 static __latent_entropy int dup_mmap(struct mm_struct *mm,
 					struct mm_struct *oldmm)
 {
+	extern int num_policy;
 	struct vm_area_struct *mpnt, *tmp, *prev, **pprev;
 	struct rb_node **rb_link, *rb_parent;
 	int retval;
@@ -485,7 +487,7 @@
 	LIST_HEAD(uf);
 
 	uprobe_start_dup_mmap();
-	if (down_write_killable(&oldmm->mmap_sem)) {
+	if (my_bpf_down_write_killable(&oldmm->mmap_sem, num_policy)) {
 		retval = -EINTR;
 		goto fail_uprobe_end;
 	}
diff -ruN SynCord-linux-base/kernel/locking/rwsem.c SynCord-linux-destination/kernel/locking/rwsem.c
--- SynCord-linux-base/kernel/locking/rwsem.c	2023-09-14 08:48:01.844831647 +0000
+++ SynCord-linux-destination/kernel/locking/rwsem.c	2023-09-15 09:08:44.354650666 +0000
@@ -19,6 +19,9 @@
 #include <linux/topology.h>
 
 #include "rwsem.h"
+#include <linux/lock_policy.h>
+#include <linux/filter.h>
+#include <linux/livepatch.h>
 
 static int __aqm_lock_slowpath(struct rwmutex *lock, long state, int is_reader, bool is_bpf, int policy_id);
 
@@ -89,7 +92,18 @@
 
 static int syncord_should_reorder(struct rwmutex *lock, struct rwaqm_node *node, struct rwaqm_node *curr, int policy_id)
 {
-	return 0;
+	if (policy_id < 0 ){
+		return 0;
+	}
+	struct bpf_prog *prog;
+	prog = bpf_prog_should_reorder_rwsem[policy_id];
+
+	struct lock_policy_args args;
+	args.numa_node = node->nid;
+	args.next_numa_node = curr->nid;
+
+	int ret = BPF_PROG_RUN(prog, &args);
+	return ret;
 }
 
 static inline uint32_t xor_random(void)
@@ -298,7 +312,7 @@
 			cmp = syncord_should_reorder(lock,node,curr,policy_id);
 		} 
 		else {
-			cmp = syncord_should_reorder(lock,node,curr,0);
+			cmp = syncord_should_reorder(lock,node,curr,-1);
 		}
 		
                 /* Check if curr->nid is same as nid */
diff -ruN SynCord-linux-base/kernel/sys.c SynCord-linux-destination/kernel/sys.c
--- SynCord-linux-base/kernel/sys.c	2023-09-13 14:41:35.689367032 +0000
+++ SynCord-linux-destination/kernel/sys.c	2023-09-15 09:09:58.770607627 +0000
@@ -42,6 +42,7 @@
 #include <linux/syscore_ops.h>
 #include <linux/version.h>
 #include <linux/ctype.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/compat.h>
 #include <linux/syscalls.h>
diff -ruN SynCord-linux-base/mm/madvise.c SynCord-linux-destination/mm/madvise.c
--- SynCord-linux-base/mm/madvise.c	2023-09-13 14:41:59.209325770 +0000
+++ SynCord-linux-destination/mm/madvise.c	2023-09-15 09:08:47.834648599 +0000
@@ -27,6 +27,7 @@
 #include <linux/swapops.h>
 #include <linux/shmem_fs.h>
 #include <linux/mmu_notifier.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/tlb.h>
 
@@ -1082,7 +1083,8 @@
 
 	write = madvise_need_mmap_write(behavior);
 	if (write) {
-		if (down_write_killable(&current->mm->mmap_sem))
+		extern int num_policy;
+		if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 			return -EINTR;
 	} else {
 		down_read(&current->mm->mmap_sem);
diff -ruN SynCord-linux-base/mm/mlock.c SynCord-linux-destination/mm/mlock.c
--- SynCord-linux-base/mm/mlock.c	2023-09-13 14:41:59.213325766 +0000
+++ SynCord-linux-destination/mm/mlock.c	2023-09-15 09:08:47.706648674 +0000
@@ -23,6 +23,7 @@
 #include <linux/hugetlb.h>
 #include <linux/memcontrol.h>
 #include <linux/mm_inline.h>
+#include <linux/my_bpf_down_write.h>
 
 #include "internal.h"
 
@@ -670,6 +671,7 @@
 
 static __must_check int do_mlock(unsigned long start, size_t len, vm_flags_t flags)
 {
+	extern int num_policy;
 	unsigned long locked;
 	unsigned long lock_limit;
 	int error = -ENOMEM;
@@ -686,7 +688,7 @@
 	lock_limit >>= PAGE_SHIFT;
 	locked = len >> PAGE_SHIFT;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	locked += current->mm->locked_vm;
@@ -735,6 +737,7 @@
 
 SYSCALL_DEFINE2(munlock, unsigned long, start, size_t, len)
 {
+	extern int num_policy;
 	int ret;
 
 	start = untagged_addr(start);
@@ -742,7 +745,7 @@
 	len = PAGE_ALIGN(len + (offset_in_page(start)));
 	start &= PAGE_MASK;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 	ret = apply_vma_lock_flags(start, len, 0);
 	up_write(&current->mm->mmap_sem);
@@ -798,6 +801,7 @@
 
 SYSCALL_DEFINE1(mlockall, int, flags)
 {
+	extern int num_policy;
 	unsigned long lock_limit;
 	int ret;
 
@@ -811,7 +815,7 @@
 	lock_limit = rlimit(RLIMIT_MEMLOCK);
 	lock_limit >>= PAGE_SHIFT;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	ret = -ENOMEM;
@@ -827,9 +831,10 @@
 
 SYSCALL_DEFINE0(munlockall)
 {
+	extern int num_policy;
 	int ret;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 	ret = apply_mlockall_flags(0);
 	up_write(&current->mm->mmap_sem);
diff -ruN SynCord-linux-base/mm/mmap.c SynCord-linux-destination/mm/mmap.c
--- SynCord-linux-base/mm/mmap.c	2023-09-14 08:48:01.876831820 +0000
+++ SynCord-linux-destination/mm/mmap.c	2023-09-15 09:08:48.294648325 +0000
@@ -47,6 +47,7 @@
 #include <linux/pkeys.h>
 #include <linux/oom.h>
 #include <linux/sched/mm.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uaccess.h>
 #include <asm/cacheflush.h>
@@ -192,6 +193,7 @@
 		struct list_head *uf);
 SYSCALL_DEFINE1(brk, unsigned long, brk)
 {
+	extern int num_policy;
 	unsigned long retval;
 	unsigned long newbrk, oldbrk, origbrk;
 	struct mm_struct *mm = current->mm;
@@ -203,7 +205,7 @@
 
 	brk = untagged_addr(brk);
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	origbrk = mm->brk;
@@ -2858,11 +2860,12 @@
 
 static int __vm_munmap(unsigned long start, size_t len, bool downgrade)
 {
+	extern int num_policy;
 	int ret;
 	struct mm_struct *mm = current->mm;
 	LIST_HEAD(uf);
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	ret = __do_munmap(mm, start, len, &uf, downgrade);
@@ -2901,6 +2904,7 @@
 SYSCALL_DEFINE5(remap_file_pages, unsigned long, start, unsigned long, size,
 		unsigned long, prot, unsigned long, pgoff, unsigned long, flags)
 {
+	extern int num_policy;
 
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
@@ -2923,7 +2927,7 @@
 	if (pgoff + (size >> PAGE_SHIFT) < pgoff)
 		return ret;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	vma = find_vma(mm, start);
@@ -3073,6 +3077,7 @@
 
 int vm_brk_flags(unsigned long addr, unsigned long request, unsigned long flags)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	unsigned long len;
 	int ret;
@@ -3085,7 +3090,7 @@
 	if (!len)
 		return 0;
 
-	if (down_write_killable(&mm->mmap_sem))
+	if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	ret = do_brk_flags(addr, len, flags, &uf);
diff -ruN SynCord-linux-base/mm/mprotect.c SynCord-linux-destination/mm/mprotect.c
--- SynCord-linux-base/mm/mprotect.c	2023-09-13 14:41:59.213325766 +0000
+++ SynCord-linux-destination/mm/mprotect.c	2023-09-15 09:08:48.034648479 +0000
@@ -32,6 +32,7 @@
 #include <asm/cacheflush.h>
 #include <asm/mmu_context.h>
 #include <asm/tlbflush.h>
+#include <linux/my_bpf_down_write.h>
 
 #include "internal.h"
 
@@ -452,6 +453,7 @@
 static int do_mprotect_pkey(unsigned long start, size_t len,
 		unsigned long prot, int pkey)
 {
+	extern int num_policy;
 	unsigned long nstart, end, tmp, reqprot;
 	struct vm_area_struct *vma, *prev;
 	int error = -EINVAL;
@@ -478,7 +480,7 @@
 
 	reqprot = prot;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	/*
diff -ruN SynCord-linux-base/mm/mremap.c SynCord-linux-destination/mm/mremap.c
--- SynCord-linux-base/mm/mremap.c	2023-09-13 14:41:59.213325766 +0000
+++ SynCord-linux-destination/mm/mremap.c	2023-09-15 09:08:47.890648565 +0000
@@ -24,6 +24,7 @@
 #include <linux/uaccess.h>
 #include <linux/mm-arch-hooks.h>
 #include <linux/userfaultfd_k.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <asm/cacheflush.h>
 #include <asm/tlbflush.h>
@@ -596,6 +597,7 @@
 		unsigned long, new_len, unsigned long, flags,
 		unsigned long, new_addr)
 {
+	extern int num_policy;
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
 	unsigned long ret = -EINVAL;
@@ -629,7 +631,7 @@
 	if (!new_len)
 		return ret;
 
-	if (down_write_killable(&current->mm->mmap_sem))
+	if (my_bpf_down_write_killable(&current->mm->mmap_sem, num_policy))
 		return -EINTR;
 
 	if (flags & MREMAP_FIXED) {
diff -ruN SynCord-linux-base/mm/util.c SynCord-linux-destination/mm/util.c
--- SynCord-linux-base/mm/util.c	2023-09-14 08:48:01.876831820 +0000
+++ SynCord-linux-destination/mm/util.c	2023-09-15 09:08:47.698648679 +0000
@@ -23,6 +23,7 @@
 #include <linux/processor.h>
 #include <linux/sizes.h>
 #include <linux/compat.h>
+#include <linux/my_bpf_down_write.h>
 
 #include <linux/uaccess.h>
 
@@ -491,7 +492,8 @@
 
 	ret = security_mmap_file(file, prot, flag);
 	if (!ret) {
-		if (down_write_killable(&mm->mmap_sem))
+		extern int num_policy;
+		if (my_bpf_down_write_killable(&mm->mmap_sem, num_policy))
 			return -EINTR;
 		ret = do_mmap_pgoff(file, addr, len, prot, flag, pgoff,
 				    &populate, &uf);
