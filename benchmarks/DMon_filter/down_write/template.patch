diff -ruN SynCord-linux-rwsem/kernel/bpf/inode.c SynCord-linux-another/kernel/bpf/inode.c
--- SynCord-linux-rwsem/kernel/bpf/inode.c	2023-09-13 09:25:12.842796129 +0000
+++ SynCord-linux-another/kernel/bpf/inode.c	2023-09-13 14:21:01.903817230 +0000
@@ -701,3 +701,77 @@
 	return ret;
 }
 fs_initcall(bpf_init);
+
+
+#include "kpatch-macros.h"
+#define MAX_POLICY 5
+
+static inline __u64 ptr_to_u64(const void *ptr)
+{
+    return (__u64) (unsigned long) ptr;
+}
+
+static void *get_pinned_bpf_obj(const char *pathname){
+	struct inode *inode;
+	struct path path;
+	void *raw;
+	int ret;
+
+	/* Let's get BPF prog 1 */
+	ret = kern_path(pathname, LOOKUP_FOLLOW, &path);
+	if (ret){
+		printk("[syncord] %s failed\n", pathname);
+		return ERR_PTR(ret);
+	}
+
+	inode = d_backing_inode(path.dentry);
+	ret = inode_permission(inode, ACC_MODE(2));
+	if(ret){
+		printk("[syncord] perm error\n");
+		path_put(&path);
+		return ERR_PTR(ret);
+	}
+
+	raw = bpf_any_get(inode->i_private, BPF_TYPE_PROG);
+	if(!IS_ERR(raw)){
+		touch_atime(&path);
+	}
+	else{
+		printk("[syncord] raw error\n");
+		path_put(&path);
+		return ERR_PTR(ret);
+	}
+
+	path_put(&path);
+	return raw;
+}
+
+static int pre_patch_callback(patch_object *obj)
+{
+	extern int num_policy;
+	extern void *bpf_prog_should_reorder_rwsem[MAX_POLICY];
+
+	if(num_policy < 4)
+		num_policy++;
+	else
+		return -1;
+
+	bpf_prog_should_reorder_rwsem[num_policy] = get_pinned_bpf_obj("/sys/fs/bpf/numa-grouping");
+	if(IS_ERR(bpf_prog_should_reorder_rwsem[num_policy])){
+		printk("[syncord] bpf_policy failed\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static void post_unpatch_callback(patch_object *obj) {
+	extern int num_policy;
+	extern void *bpf_prog_should_reorder_rwsem[MAX_POLICY];
+
+	bpf_prog_should_reorder_rwsem[num_policy] = NULL;
+	num_policy--;
+	klp_shadow_free_all(0, NULL);
+}
+KPATCH_PRE_PATCH_CALLBACK(pre_patch_callback);
+KPATCH_POST_UNPATCH_CALLBACK(post_unpatch_callback);
diff -ruN SynCord-linux-rwsem/kernel/locking/rwsem.c SynCord-linux-another/kernel/locking/rwsem.c
--- SynCord-linux-rwsem/kernel/locking/rwsem.c	2023-09-13 13:49:07.750108142 +0000
+++ SynCord-linux-another/kernel/locking/rwsem.c	2023-09-13 14:53:48.443509877 +0000
@@ -19,6 +19,9 @@
 #include <linux/topology.h>
 
 #include "rwsem.h"
+#include <linux/lock_policy.h>
+#include <linux/filter.h>
+#include <linux/livepatch.h>
 
 static int __aqm_lock_slowpath(struct rwmutex *lock, long state, int is_reader, bool is_bpf, int policy_id);
 
@@ -89,7 +92,18 @@
 
 static int syncord_should_reorder(struct rwmutex *lock, struct rwaqm_node *node, struct rwaqm_node *curr, int policy_id)
 {
-	return 0;
+	if (policy_id < 0 ){
+		return 0;
+	}
+	struct bpf_prog *prog;
+	prog = bpf_prog_should_reorder_rwsem[policy_id];
+
+	struct lock_policy_args args;
+	args.numa_node = node->nid;
+	args.next_numa_node = curr->nid;
+
+	int ret = BPF_PROG_RUN(prog, &args);
+	return ret;
 }
 
 static inline uint32_t xor_random(void)
@@ -298,7 +312,7 @@
 			cmp = syncord_should_reorder(lock,node,curr,policy_id);
 		} 
 		else {
-			cmp = syncord_should_reorder(lock,node,curr,0);
+			cmp = syncord_should_reorder(lock,node,curr,-1);
 		}
 		
                 /* Check if curr->nid is same as nid */
